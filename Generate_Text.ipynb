{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate_Text.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "YQauK_ntCECx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "07dfd51d-a29d-4a37-a2c7-7c26f24c79ad"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OfyLZsESCOf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DXTn4mO3C0TA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/tokenizer_s2_1M.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IVrnTrZSDAyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/sequences_digit_s2_1M.pkl', 'rb') as f:\n",
        "    sequences_digit = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7S_Y9NlDDPs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJJi1q-xDSCN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDmAZuizDatE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "322fac01-f8a2-4bf4-b20d-1319e940589a"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "print(\"Loading pre-trained weight\")\n",
        "model = load_model('drive/My Drive/Machine_Learning-prj/vietnamese_language_model/51_weight_language_model.h5')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pre-trained weight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wgucT5JLHlBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "696a512d-5b2f-4b6e-ca4f-3a3fc535d3db"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyvi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/5f/431512f630932055b09ad089c6d515173290cd5c2956d773377478792948/pyvi-0.0.9.1.tar.gz (5.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.19.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.11.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K    100% |████████████████████████████████| 757kB 15.0MB/s \n",
            "\u001b[?25hCollecting tabulate (from sklearn-crfsuite->pyvi)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.26.0)\n",
            "Building wheels for collected packages: pyvi, tabulate\n",
            "  Running setup.py bdist_wheel for pyvi ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b8/cb/53/54834bcc54e39de0e83897064a70335902e15ac84b44125b1a\n",
            "  Running setup.py bdist_wheel for tabulate ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\n",
            "Successfully built pyvi tabulate\n",
            "Installing collected packages: python-crfsuite, tabulate, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.6 pyvi-0.0.9.1 sklearn-crfsuite-0.3.6 tabulate-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kp9TiI9BECFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyvi import ViTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "\n",
        "def clean_document(doc):\n",
        "    doc = ViTokenizer.tokenize(doc)\n",
        "    doc = doc.lower() #Lower\n",
        "    \n",
        "    tokens = doc.split() #Split in_to words\n",
        "    \n",
        "    table = str.maketrans('', '', string.punctuation.replace(\"_\", \"\")) #Remove all punctuation\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    \n",
        "    tokens = [word for word in tokens if word]\n",
        "        \n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N445rVG9LHeg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def preprocess_input(doc):\n",
        "    tokens = clean_document(doc)\n",
        "    tokens = tokenizer.texts_to_sequences(tokens)\n",
        "    tokens = pad_sequences([tokens], maxlen=50, truncating='pre')\n",
        "    return np.reshape(tokens, (1,50))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBaN3WLLMGrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(text_input, n_words):\n",
        "    tokens = preprocess_input(text_input)\n",
        "    for _ in range(n_words):\n",
        "        next_digit = model.predict_classes(tokens)\n",
        "        tokens = np.append(tokens, next_digit)\n",
        "        tokens = np.delete(tokens, 0)\n",
        "        tokens = np.reshape(tokens, (1, 50))\n",
        "    \n",
        "    # Mapping to text  \n",
        "    tokens = np.reshape(tokens, (50))\n",
        "    out_word = []\n",
        "    for token in tokens:\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == token:\n",
        "                out_word.append(word)\n",
        "                break\n",
        "\n",
        "    return ' '.join(out_word)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LriOboYYMnRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d994a5e9-2b62-4e97-e47a-2033664664d8"
      },
      "cell_type": "code",
      "source": [
        "seq = 'đường phố ở việt nam'\n",
        "generate_text(text_input=seq, n_words=25)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'đường_phố ở việt_nam tạo nhiều nét của các nghệ_nhân chính_trị khác nhiều tác_phẩm được coi là nơi có nhiều cột đồ thu_hút được được đánh_giá là có giá_trị'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "nOLPc5AWXtU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "a7fde353-c868-4330-e042-a8ae88e2f24d"
      },
      "cell_type": "code",
      "source": [
        "seq = 'Tại buổi đối thoại, nhiều doanh nghiệp cho biết hằng năm họ phải tiếp nhiều đoàn thanh tra, kiểm tra từ các cấp, việc này vô tình gây mất thời gian, phiền hà'\n",
        "generate_text(text_input=seq, n_words=25)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'buổi đối_thoại nhiều doanh_nghiệp cho biết hằng năm họ phải tiếp nhiều đoàn thanh_tra kiểm_tra từ các cấp việc này vô_tình gây mất thời_gian phiền_hà lớn hơn cả năm nay các nhà đầu_tư lại thất_nghiệp vừa minh_bạch 2 usd trong khi nhà_nước có_thể xuất mức lãi_suất đang được tiếp_tục tiếp_tục'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "On_HTgB8Q2a-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}